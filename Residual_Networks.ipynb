{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohith033/ResidualNetworks/blob/main/Residual_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GQyI43cYE7o"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNHYsCziYE7s"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e85fEFXAYE7s"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjmDpCmaYE7t"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from resnets_utils import *\n",
        "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "from test_utils import summary, comparator\n",
        "import public_tests\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZwXNnUoYE7x"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgLI8_pDYE7y"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NImaJk9EYE7y"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdligR76YE7z"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb2qRDFsYE7z"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhL-KRRYYE70"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-0017b68317ffa974",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Rcf8Rm0KYE71"
      },
      "outputs": [],
      "source": [
        "# UNQ_C1\n",
        "# GRADED FUNCTION: identity_block\n",
        "\n",
        "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    training -- True: Behave in training mode\n",
        "                False: Behave in inference mode\n",
        "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    ### START CODE HERE\n",
        "    ## Second component of main path (≈3 lines)\n",
        "    ## Set the padding = 'same'\n",
        "    X = Conv2D(filters = F2, kernel_size = f, strides = (1,1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ## Third component of main path (≈2 lines)\n",
        "    ## Set the padding = 'valid'\n",
        "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
        "#     X = Activation('relu')(X) \n",
        "    \n",
        "    ## Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = tf.keras.layers.Add()([X_shortcut,X])\n",
        "    X = Activation('relu')(X)\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-e73a8466b807e261",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7qc0ynJvYE72",
        "outputId": "5572c13b-18db-47c1-9ca2-ead0f55a122d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mWith training=False\u001b[0m\n",
            "\n",
            "[[[  0.        0.        0.        0.     ]\n",
            "  [  0.        0.        0.        0.     ]]\n",
            "\n",
            " [[192.71234 192.71234 192.71234  96.85617]\n",
            "  [ 96.85617  96.85617  96.85617  48.92808]]\n",
            "\n",
            " [[578.1371  578.1371  578.1371  290.5685 ]\n",
            "  [290.5685  290.5685  290.5685  146.78426]]]\n",
            "96.85617\n",
            "\n",
            "\u001b[1mWith training=True\u001b[0m\n",
            "\n",
            "[[[0.      0.      0.      0.     ]\n",
            "  [0.      0.      0.      0.     ]]\n",
            "\n",
            " [[0.40739 0.40739 0.40739 0.40739]\n",
            "  [0.40739 0.40739 0.40739 0.40739]]\n",
            "\n",
            " [[4.99991 4.99991 4.99991 3.25948]\n",
            "  [3.25948 3.25948 3.25948 2.40739]]]\n",
            "\u001b[32mAll tests passed!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(1)\n",
        "X1 = np.ones((1, 4, 4, 3)) * -1\n",
        "X2 = np.ones((1, 4, 4, 3)) * 1\n",
        "X3 = np.ones((1, 4, 4, 3)) * 3\n",
        "\n",
        "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
        "\n",
        "A3 = identity_block(X, f=2, filters=[4, 4, 3],\n",
        "                   initializer=lambda seed=0:constant(value=1),\n",
        "                   training=False)\n",
        "print('\\033[1mWith training=False\\033[0m\\n')\n",
        "A3np = A3.numpy()\n",
        "print(np.around(A3.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))\n",
        "resume = A3np[:,(0,-1),:,:].mean(axis = 3)\n",
        "print(resume[1, 1, 0])\n",
        "\n",
        "print('\\n\\033[1mWith training=True\\033[0m\\n')\n",
        "np.random.seed(1)\n",
        "A4 = identity_block(X, f=2, filters=[3, 3, 3],\n",
        "                   initializer=lambda seed=0:constant(value=1),\n",
        "                   training=True)\n",
        "print(np.around(A4.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))\n",
        "\n",
        "public_tests.identity_block_test(identity_block)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZioVrgHYE79"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kTC8SkMYE79"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-df47af4847e5335f",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "11T6yCg0YE79"
      },
      "outputs": [],
      "source": [
        "# UNQ_C2\n",
        "# GRADED FUNCTION: convolutional_block\n",
        "\n",
        "def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in Figure 4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    training -- True: Behave in training mode\n",
        "                False: Behave in inference mode\n",
        "    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer, \n",
        "                   also called Xavier uniform initializer.\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (m, n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    \n",
        "    # First component of main path glorot_uniform(seed=0)\n",
        "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training=training)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ### START CODE HERE\n",
        "    \n",
        "    ## Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = f, strides = (1, 1), padding='same', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training=training)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    ## Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training=training)\n",
        "\n",
        "    \n",
        "    X_shortcut = Conv2D(filters = F3, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut,training = training)\n",
        "#     X = Activation('relu')(X)\n",
        "\n",
        "    \n",
        "    ### END CODE HERE\n",
        "\n",
        "    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-95c291eb244218fe",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "scrolled": true,
        "id": "aaqevTQMYE7-",
        "outputId": "a19b3dd3-0b1d-41b7-81c7-ede7eb7b162b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[0.         0.66683817 0.         0.         0.88853896 0.5274254 ]\n",
            "  [0.         0.65053666 0.         0.         0.89592844 0.49965227]]\n",
            "\n",
            " [[0.         0.6312079  0.         0.         0.8636247  0.47643146]\n",
            "  [0.         0.5688321  0.         0.         0.85534114 0.41709304]]], shape=(2, 2, 6), dtype=float32)\n",
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "from outputs import convolutional_block_output1, convolutional_block_output2\n",
        "np.random.seed(1)\n",
        "#X = np.random.randn(3, 4, 4, 6).astype(np.float32)\n",
        "X1 = np.ones((1, 4, 4, 3)) * -1\n",
        "X2 = np.ones((1, 4, 4, 3)) * 1\n",
        "X3 = np.ones((1, 4, 4, 3)) * 3\n",
        "\n",
        "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
        "\n",
        "A = convolutional_block(X, f = 2, filters = [2, 4, 6], training=False)\n",
        "\n",
        "assert type(A) == EagerTensor, \"Use only tensorflow and keras functions\"\n",
        "assert tuple(tf.shape(A).numpy()) == (3, 2, 2, 6), \"Wrong shape.\"\n",
        "assert np.allclose(A.numpy(), convolutional_block_output1), \"Wrong values when training=False.\"\n",
        "print(A[0])\n",
        "\n",
        "B = convolutional_block(X, f = 2, filters = [2, 4, 6], training=True)\n",
        "assert np.allclose(B.numpy(), convolutional_block_output2), \"Wrong values when training=True.\"\n",
        "\n",
        "print('\\033[92mAll tests passed!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dDyhS4tYE7_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trHqNEanYE7_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-10dc95a4cf6275b9",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "sBY7ztuiYE7_"
      },
      "outputs": [],
      "source": [
        "# UNQ_C3\n",
        "# GRADED FUNCTION: ResNet50\n",
        "\n",
        "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
        "    \"\"\"\n",
        "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "\n",
        "    ### START CODE HERE\n",
        "    \n",
        "    ## Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X,3,[128,128,512],2)\n",
        "    X = identity_block(X,3,[128,128,512])\n",
        "    X = identity_block(X,3,[128,128,512])\n",
        "    X = identity_block(X,3,[128,128,512])\n",
        "    \n",
        "    ## Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X,3,[256,256,1024],2)\n",
        "    X = identity_block(X,3,[256,256,1024])\n",
        "    X = identity_block(X,3,[256,256,1024])\n",
        "    X = identity_block(X,3,[256,256,1024])\n",
        "    #X = convolutional_block(X,3,[256,256,1024])\n",
        "    X = identity_block(X,3,[256,256,1024])\n",
        "    X = identity_block(X,3,[256,256,1024])\n",
        "\n",
        "    ## Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X,3,[512,512,2048],2)\n",
        "    X = identity_block(X,3,[512,512,2048])\n",
        "    X = identity_block(X,3,[512,512,2048])\n",
        "\n",
        "    ## AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D(pool_size=(2, 2))(X)\n",
        "    \n",
        "    ### END CODE HERE\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WWnq5gEYE8A"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xvw4DvzYE8A",
        "outputId": "f55bb977-af8e-4a51-ba1b-8009d316393a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 70, 70, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 32, 32, 64)   9472        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 32, 32, 64)   256         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 32, 32, 64)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 15, 15, 64)   0           activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 15, 15, 64)   4160        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 15, 15, 64)   256         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 15, 15, 64)   0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 15, 15, 64)   36928       activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 15, 15, 64)   256         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 15, 15, 64)   0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 15, 15, 256)  16640       activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 15, 15, 256)  16640       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 15, 15, 256)  1024        conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 15, 15, 256)  1024        conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 15, 15, 256)  0           batch_normalization_63[0][0]     \n",
            "                                                                 batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 15, 15, 256)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 15, 15, 64)   16448       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 15, 15, 64)   256         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 15, 15, 64)   0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 15, 15, 64)   36928       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 15, 15, 64)   256         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 15, 15, 64)   0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 15, 15, 256)  16640       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 15, 15, 256)  1024        conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 15, 15, 256)  0           activation_50[0][0]              \n",
            "                                                                 batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 15, 15, 256)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 15, 15, 64)   16448       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 15, 15, 64)   256         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 15, 15, 64)   0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 15, 15, 64)   36928       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 15, 15, 64)   256         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 15, 15, 64)   0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 15, 15, 256)  16640       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 15, 15, 256)  1024        conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 15, 15, 256)  0           activation_53[0][0]              \n",
            "                                                                 batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 15, 15, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 128)    32896       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 128)    512         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 8, 8, 128)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 8, 8, 128)    147584      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 8, 8, 128)    512         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 8, 8, 128)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 8, 8, 512)    66048       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 8, 8, 512)    131584      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 8, 8, 512)    2048        conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 8, 8, 512)    2048        conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 8, 8, 512)    0           batch_normalization_73[0][0]     \n",
            "                                                                 batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 8, 8, 512)    0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 128)    65664       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 128)    512         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 8, 8, 128)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 128)    147584      activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 128)    512         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 8, 8, 128)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 512)    66048       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 512)    2048        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 8, 8, 512)    0           activation_59[0][0]              \n",
            "                                                                 batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 8, 8, 512)    0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 128)    65664       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 128)    512         conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 8, 8, 128)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 128)    147584      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 128)    512         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 8, 8, 128)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 512)    66048       activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 512)    2048        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 8, 8, 512)    0           activation_62[0][0]              \n",
            "                                                                 batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 8, 8, 512)    0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 128)    65664       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 128)    512         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 8, 8, 128)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 128)    147584      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 128)    512         conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 8, 8, 128)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 512)    66048       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 512)    2048        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 8, 8, 512)    0           activation_65[0][0]              \n",
            "                                                                 batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 8, 8, 512)    0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 4, 4, 256)    131328      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 4, 4, 256)    1024        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 4, 4, 256)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 4, 4, 256)    590080      activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 4, 4, 256)    1024        conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 4, 4, 256)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 4, 4, 1024)   263168      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 4, 4, 1024)   525312      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 4, 4, 1024)   4096        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 4, 4, 1024)   4096        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 4, 4, 1024)   0           batch_normalization_86[0][0]     \n",
            "                                                                 batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 4, 4, 1024)   0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 4, 4, 256)    262400      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 4, 4, 256)    1024        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 4, 4, 256)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 4, 4, 256)    590080      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 4, 4, 256)    1024        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 4, 4, 256)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 4, 4, 1024)   263168      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 4, 4, 1024)   4096        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 4, 4, 1024)   0           activation_71[0][0]              \n",
            "                                                                 batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 4, 4, 1024)   0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 4, 4, 256)    262400      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 4, 4, 256)    1024        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 4, 4, 256)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 4, 4, 256)    590080      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 4, 4, 256)    1024        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 4, 4, 256)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 4, 4, 1024)   263168      activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 4, 4, 1024)   4096        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 4, 4, 1024)   0           activation_74[0][0]              \n",
            "                                                                 batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 4, 4, 1024)   0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 4, 4, 256)    262400      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 4, 4, 256)    1024        conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 4, 4, 256)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 4, 4, 256)    590080      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 4, 4, 256)    1024        conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 4, 4, 256)    0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 4, 4, 1024)   263168      activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 4, 4, 1024)   4096        conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 4, 4, 1024)   0           activation_77[0][0]              \n",
            "                                                                 batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 4, 4, 1024)   0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 4, 4, 256)    262400      activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 4, 4, 256)    1024        conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 4, 4, 256)    0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 4, 4, 256)    590080      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 4, 4, 256)    1024        conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 4, 4, 256)    0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 4, 4, 1024)   263168      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 4, 4, 1024)   4096        conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 4, 4, 1024)   0           activation_80[0][0]              \n",
            "                                                                 batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 4, 4, 1024)   0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 4, 4, 256)    262400      activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 4, 4, 256)    1024        conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 4, 4, 256)    0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 4, 4, 256)    590080      activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 4, 4, 256)    1024        conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 4, 4, 256)    0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 4, 4, 1024)   263168      activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 4, 4, 1024)   4096        conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 4, 4, 1024)   0           activation_83[0][0]              \n",
            "                                                                 batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 4, 4, 1024)   0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 2, 2, 512)    524800      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 2, 2, 512)    2048        conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 2, 2, 512)    0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 2, 2, 512)    2359808     activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 2, 2, 512)    2048        conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 2, 2, 512)    0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 2, 2, 2048)   2099200     activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 2, 2, 2048)   8192        conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 2, 2, 2048)   8192        conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 2, 2, 2048)   0           batch_normalization_105[0][0]    \n",
            "                                                                 batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 2, 2, 2048)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 2, 2, 512)    1049088     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 2, 2, 512)    2048        conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 2, 2, 512)    0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 2, 2, 512)    2359808     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 2, 2, 512)    2048        conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 2, 2, 512)    0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 2, 2, 2048)   8192        conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 2, 2, 2048)   0           activation_89[0][0]              \n",
            "                                                                 batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 2, 2, 2048)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 2, 2, 512)    1049088     activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 2, 2, 512)    2048        conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 2, 2, 512)    0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 2, 2, 512)    2359808     activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 2, 2, 512)    2048        conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 2, 2, 512)    0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 2, 2, 2048)   1050624     activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 2, 2, 2048)   8192        conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 2, 2, 2048)   0           activation_92[0][0]              \n",
            "                                                                 batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 2, 2, 2048)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 2048)   0           activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2048)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 6)            12294       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,600,006\n",
            "Trainable params: 23,546,886\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-866b891ec47ccb7b",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "scrolled": true,
        "id": "Y15MMezeYE8B",
        "outputId": "6bb54595-d42e-461d-f481-0272febfa311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mAll tests passed!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from outputs import ResNet50_summary\n",
        "\n",
        "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
        "\n",
        "comparator(summary(model), ResNet50_summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea7uPBhQYE8B"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl7tp8MkYE8B"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3lIMfeFYE8B"
      },
      "source": [
        "The model is now ready to be trained. The only thing you need now is a dataset!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2zKvXeHYE8B"
      },
      "source": [
        "Let's load your old friend, the SIGNS dataset.\n",
        "\n",
        "<img src=\"images/signs_data_kiank.png\" style=\"width:450px;height:250px;\">\n",
        "<caption><center> <u> <font color='purple'> <b>Figure 6</b> </u><font color='purple'>  : <b>SIGNS dataset</b> </center></caption>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "m2TtKHq5YE8C",
        "outputId": "06528084-9a38-4807-803f-9bc7751abd3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of training examples = 1080\n",
            "number of test examples = 120\n",
            "X_train shape: (1080, 64, 64, 3)\n",
            "Y_train shape: (1080, 6)\n",
            "X_test shape: (120, 64, 64, 3)\n",
            "Y_test shape: (120, 6)\n"
          ]
        }
      ],
      "source": [
        "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
        "\n",
        "# Normalize image vectors\n",
        "X_train = X_train_orig / 255.\n",
        "X_test = X_test_orig / 255.\n",
        "\n",
        "# Convert training and test labels to one hot matrices\n",
        "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
        "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZymjjOwYE8C"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "eWT_9O1KYE8C",
        "outputId": "3738e85d-0c77-441a-83f6-754c334574bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "34/34 [==============================] - 1s 29ms/step - loss: 1.9818 - accuracy: 0.4259\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 0.5154 - accuracy: 0.8185\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 0.4809 - accuracy: 0.8352\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 0.3308 - accuracy: 0.8926\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 0.3709 - accuracy: 0.8861\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 0.3099 - accuracy: 0.9009\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 0.2893 - accuracy: 0.9130\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 1s 23ms/step - loss: 0.1484 - accuracy: 0.9556\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 0.1144 - accuracy: 0.9648\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 1s 24ms/step - loss: 0.0569 - accuracy: 0.9843\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6ec41c15c0>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, Y_train, epochs = 10, batch_size = 32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riI2ImzWYE8D"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWUnwRyTYE8D"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "grh1nZoEYE8D",
        "outputId": "b7e4ddae-65ef-4cc4-af78-9f070e4316d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4069 - accuracy: 0.9000\n",
            "Loss = 0.40693002939224243\n",
            "Test Accuracy = 0.8999999761581421\n"
          ]
        }
      ],
      "source": [
        "preds = model.evaluate(X_test, Y_test)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K33fgiw8YE8E"
      },
      "source": [
        "**Expected Output**:\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            <b>Test Accuracy</b>\n",
        "        </td>\n",
        "        <td>\n",
        "           >0.80\n",
        "        </td>\n",
        "    </tr>\n",
        "\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ensWNrDxYE8E"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP6PuALSYE8E"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLwcPg9DYE8E"
      },
      "outputs": [],
      "source": [
        "pre_trained_model = tf.keras.models.load_model('resnet50.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7-8o6teYE8F",
        "outputId": "4e6b004e-46f5-4b3b-d511-5e8ef8882efc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1596 - accuracy: 0.9500\n",
            "Loss = 0.15958674252033234\n",
            "Test Accuracy = 0.949999988079071\n"
          ]
        }
      ],
      "source": [
        "preds = pre_trained_model.evaluate(X_test, Y_test)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9ZXptPpYE8F"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fspzte6wYE8F"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVMSbNK3YE8G"
      },
      "source": [
        "<a name='5'></a>  \n",
        "## Test on Your Own Image "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQFdbHKQYE8G"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyLI2mygYE8G"
      },
      "outputs": [],
      "source": [
        "img_path = 'images/my_image.jpg'\n",
        "img = image.load_img(img_path, target_size=(64, 64))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = x/255.0\n",
        "print('Input image shape:', x.shape)\n",
        "imshow(img)\n",
        "prediction = pre_trained_model.predict(x)\n",
        "print(\"Class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \", prediction)\n",
        "print(\"Class:\", np.argmax(prediction))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPca222UYE8G"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD_appaDYE8H"
      },
      "source": [
        "You can also print a summary of your model by running the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Qua17SOxYE8H"
      },
      "outputs": [],
      "source": [
        "pre_trained_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzL5d3BkYE8H"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvZh8Fe1YE8H"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Raw Cell Format",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Residual_Networks.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}